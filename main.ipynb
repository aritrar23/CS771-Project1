{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "767a412d-bbd4-4a79-b075-016a5c4fd029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ARITRA\\AppData\\Local\\Temp\\ipykernel_32612\\1335527781.py:86: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  X_test = X_test.applymap(replace_emoticon)\n",
      "C:\\Users\\ARITRA\\anaconda3\\envs\\new-env-tensorflow\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator OneHotEncoder from version 1.2.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\ARITRA\\anaconda3\\envs\\new-env-tensorflow\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.2.2 when using version 1.5.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set the random seeds for reproducibility\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)  # Python hash seed\n",
    "random.seed(SEED)                         # Python random module seed\n",
    "np.random.seed(SEED)                      # NumPy seed\n",
    "tf.random.set_seed(SEED)      \n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from joblib import dump, load\n",
    "\n",
    "# these are dummy models\n",
    "class MLModel():\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        pass\n",
    "    \n",
    "class TextSeqModel(MLModel):\n",
    "    def __init__(self) -> None:\n",
    "        # Initialization logic (if needed)\n",
    "        pass\n",
    "\n",
    "    # Load and preprocess the training and validation data\n",
    "    def one_hot_encode_digits(self, strings):\n",
    "        # Convert strings of digits into a list of digit sequences (lists of ints)\n",
    "        digit_sequences = [[int(char) for char in string] for string in strings]\n",
    "        # One-hot encode digits (0-9)\n",
    "        one_hot_encoded = np.array([tf.keras.utils.to_categorical(seq, num_classes=10) for seq in digit_sequences])\n",
    "        return one_hot_encoded\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Call the instance method with self\n",
    "        X_encoded = self.one_hot_encode_digits(X)\n",
    "        \n",
    "        # Load the model once during initialization\n",
    "        model = tf.keras.models.load_model('t3_cnn.keras')\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        predictions = model.predict(X_encoded)\n",
    "        return (predictions > 0.5).astype(\"int32\").flatten()\n",
    "\n",
    "    def predict_logits(self, X):\n",
    "        # Call the instance method with self\n",
    "        X_encoded = self.one_hot_encode_digits(X)\n",
    "        \n",
    "        # Load the model once during initialization\n",
    "        model = tf.keras.models.load_model('t3_cnn.keras')\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        predictions = model.predict(X_encoded)\n",
    "        return predictions\n",
    "\n",
    "\n",
    "class EmoticonModel(MLModel):\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    #Converting string of emoji to multiple features then one hot encode them\n",
    "    def one_hot_encode_emoticons(self, df_test):\n",
    "\n",
    "        #Converting feature to lists\n",
    "        df_test['split_emojis'] = df_test['input_emoticon'].apply(list)\n",
    "\n",
    "        #assigning only the set of feature vectors as data frame to X_test\n",
    "        X_test = pd.DataFrame(df_test['split_emojis'].tolist())\n",
    "        l=['🛠', '🙵', '🙺', '\\U0001f6da', '🛃', '🙝', '🙂', '🚬', '🙭', '😈', '🙡', '🚻']\n",
    "        def replace_emoticon(val):\n",
    "            if val in l:\n",
    "                return '😣'  # Replace with '😣' if the value is in the list l\n",
    "            return val      # Return the original value otherwise\n",
    "\n",
    "        # Apply the function to each element in the DataFrame X_test\n",
    "        X_test = X_test.applymap(replace_emoticon)\n",
    "        #Using OneHotEncoder object on X_test\n",
    "        encoder=load('encoder.pkl')\n",
    "        X_test_encoded=encoder.transform(X_test)\n",
    "\n",
    "        return X_test_encoded\n",
    "        \n",
    "\n",
    "    def predict(self, X_test):\n",
    "        #Call the instance method with self\n",
    "        X_test_encoded=self.one_hot_encode_emoticons(X_test)\n",
    "        #Load the model once during initialization\n",
    "        model=load('SVM.pkl')\n",
    "        y_pred=model.predict(X_test_encoded)\n",
    "        return y_pred\n",
    "    \n",
    "class FeatureModel(MLModel):\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        X.resize(X.shape[0], 13*768)\n",
    "        sc = load('std_scaler.bin')\n",
    "        pca = load('pca.bin')\n",
    "        X_scaled = sc.transform(X)\n",
    "        X_pca = pca.transform(X_scaled)\n",
    "        # Load the model once during initialization\n",
    "        model = tf.keras.models.load_model(\"TASK1_BEST_MODEL.keras\")\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        predictions = model.predict(X_pca)\n",
    "        return (predictions > 0.5).astype(\"int32\").flatten()\n",
    "        \n",
    "    def predict_logits(self,X):\n",
    "        X.resize(X.shape[0], 13*768)\n",
    "        sc = load('std_scaler.bin')\n",
    "        pca = load('pca.bin')\n",
    "        X_scaled = sc.transform(X)\n",
    "        X_pca = pca.transform(X_scaled)\n",
    "        # Load the model once during initialization\n",
    "        model = tf.keras.models.load_model(\"TASK1_BEST_MODEL.keras\")\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        predictions = model.predict(X_pca)\n",
    "        return predictions\n",
    "    \n",
    "class CombinedModel(MLModel):\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def predict(self, X1, X2, X3): # random predictions\n",
    "        # Step 1: Load the model from the json file\n",
    "        model_new = EmoticonModel()\n",
    "        model2 = xgb.XGBClassifier()\n",
    "        model2.load_model(\"XGB.json\")  # specify the path to your xgb.json file\n",
    "        \n",
    "        X2_encoded=model_new.one_hot_encode_emoticons(X2)\n",
    "        # Step 2: Make predictions using the loaded model and get the probabilities\n",
    "        probabilities = model2.predict_proba(X2_encoded)\n",
    "        X_emoticons_probs = probabilities[:, 1]\n",
    "        X_emoticons_probs.resize(X_emoticons_probs.shape[0],1)\n",
    "\n",
    "        model1 = FeatureModel()\n",
    "        X_array_probs = model1.predict_logits(X1)\n",
    "        \n",
    "        model3 = TextSeqModel()\n",
    "        X_text_probs = model3.predict_logits(X3)\n",
    "\n",
    "        X = np.concatenate((X_emoticons_probs, X_array_probs,X_text_probs), axis = 1)\n",
    "        scaler = load('std_scaler_combined_model.bin')\n",
    "        X_scaled = scaler.transform(X)\n",
    "    \n",
    "        # Step 1: Load the model from the json file\n",
    "        bst = xgb.XGBClassifier()\n",
    "        bst.load_model(\"XGB_FINAL.json\")  # specify the path to your xgb.json file\n",
    "        y_pred = bst.predict(X_scaled)\n",
    "        return y_pred\n",
    "\n",
    "def save_predictions_to_file(predictions, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        for pred in predictions:\n",
    "            f.write(f\"{pred}\\n\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # read datasets\n",
    "    test_feat_X = np.load(\"datasets/test/test_feature.npz\", allow_pickle=True)['features']\n",
    "    test_emoticon_X = pd.read_csv(\"datasets/test/test_emoticon.csv\")\n",
    "    test_seq_X = pd.read_csv(\"datasets/test/test_text_seq.csv\")['input_str'].tolist()\n",
    "\n",
    "    \n",
    "    # your trained models \n",
    "    feature_model = FeatureModel()\n",
    "    text_model = TextSeqModel()\n",
    "    emoticon_model  = EmoticonModel()\n",
    "    best_model = CombinedModel()\n",
    "    \n",
    "    # predictions from your trained models\n",
    "    pred_feat = feature_model.predict(test_feat_X)\n",
    "    pred_emoticons = emoticon_model.predict(test_emoticon_X)\n",
    "    # pred_text = text_model.predict(test_seq_X)\n",
    "    # pred_combined = best_model.predict(test_feat_X, test_emoticon_X, test_seq_X)\n",
    "    \n",
    "    # saving prediction to text files\n",
    "    save_predictions_to_file(pred_feat, \"pred_feat.txt\")\n",
    "    save_predictions_to_file(pred_emoticons, \"pred_emoticon.txt\")\n",
    "    # save_predictions_to_file(pred_text, \"pred_text.txt\")\n",
    "    # save_predictions_to_file(pred_combined, \"pred_combined.txt\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3286ddb-b207-4e60-8b22-3f8cf485b664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common emoticon is: 😣, appearing 4464 times.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Assuming test_emoticon_X is your DataFrame and 'split_emoticon' is the feature column\n",
    "# Flatten the list of emoticons across all rows in the 'split_emoticon' column\n",
    "all_emoticons = [emoticon for sublist in test_emoticon_X['split_emojis'] for emoticon in sublist]\n",
    "\n",
    "# Use Counter to count the occurrences of each emoticon\n",
    "emoticon_counter = Counter(all_emoticons)\n",
    "\n",
    "# Find the most common emoticon\n",
    "most_common_emoticon, count = emoticon_counter.most_common(1)[0]\n",
    "\n",
    "# Output the most common emoticon and its count\n",
    "print(f\"The most common emoticon is: {most_common_emoticon}, appearing {count} times.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607fec17-346a-4181-8eb5-ff0e8b2cec5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
